{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float:center\" src=\"img/acquire.png\" width=300/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Acquire the Data\n",
    "\n",
    "We have downloaded the data from https://www.backblaze.com/hard-drive-test-data.html. We are using the 2013 data dump as 2015 data dump is relatively large. The techniques we are using to acquire the data for 2013, \n",
    "can be applied to 2015 data dump as well.\n",
    "\n",
    "When you download the 2013 data, you get a zipped package consisting of 266 files.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do we read from 266 files?\n",
    "\n",
    "As the data is spread across 266 files, it is hard for us to read data. Is there a way I can put all this data into one single place , so that my reads are easier?\n",
    "\n",
    "** There are 2 options **\n",
    "*  1. Merge all the data into one single big csv file\n",
    "*  2. Push the data into a database\n",
    "\n",
    "For this example let us go the **database** path. For the simple reason, keeping a big csv file in memory is very expensive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Formats**\n",
    "- csv files\n",
    "\n",
    "**Database**\n",
    "- SQLite\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating entries in SQLite using pandas and sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/nischal/code/intro-python-data-science/hard-disk/hard-disk-test.db\n"
     ]
    }
   ],
   "source": [
    "sql_path = os.getcwd()\n",
    "sql_path = sql_path+\"/hard-disk-test.db\"\n",
    "print sql_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we have created a small db for you to use \n",
    "# you will be able to see hard-disk-test.db in repository you have cloned\n",
    "# this command creates the connection to database\n",
    "engine = create_engine('sqlite:///'+sql_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/nischal/code/intro-python-data-science/hard-disk/data\n"
     ]
    }
   ],
   "source": [
    "# we are getting the directory data to read files\n",
    "path = os.path.join(os.getcwd(),'data')\n",
    "print path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float:center\" src=\"img/files-database.jpg\" width=150/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013-04-11.csv\n",
      "2013-04-10.csv\n",
      "loading data done with rows 42390\n"
     ]
    }
   ],
   "source": [
    "# we are reading csv files from the directory and laoding them into the database\n",
    "no_of_files = 0\n",
    "total_rows = 0\n",
    "for file in os.listdir(path):\n",
    "    if str(file).endswith(\".csv\"):\n",
    "        print file\n",
    "        inp_df = pd.read_csv(os.path.join(path,file))\n",
    "        inp_df.to_sql(\"data\",engine,index=False,chunksize=None,if_exists='append')\n",
    "        total_rows = total_rows + inp_df.shape[0]\n",
    "\n",
    "print 'loading data done with rows '+str(total_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# you can now put all the 266 csv files into the data directory and the above piece of code will push all the data\n",
    "# into the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
